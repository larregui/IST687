---
title: "Group 4 Project"
author: "Laura Larregui, Angela Garcia, John Christman"
date: "11/18/2019"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r readWines}
readURL <- function(inputURL)  #Begin function named readURL that takes a URL
{
  csvFile <- read.csv(url(inputURL), sep = ';')  #assign the results of the URL call as a csv file to a dataframe named csvFile. Added sep = ';' to seperate the data into columns
  return(csvFile)  # return the dataframe
}

redWine <- readURL("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv")
whiteWine <- readURL("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv")

str(redWine)
str(whiteWine)
summary(redWine)
summary(whiteWine)
```

```{r cleanWine}
#THe datasets only have one column of data.  The column names are separated by periods the data by semi-colons
#1. Create columns 
#2.  separate the data into the columns
#3.  Verify no NAs
redWine <- na.omit(redWine)
whiteWine<-na.omit (whiteWine)

```

```{r Standard Deviations}
#Quality Standard Deviations
sd(redWine$quality)
sd(whiteWine$quality)

#Red wine Standard Deviations
sd(redWine$quality)
sd(redWine$alcohol)
sd(redWine$residual.sugar)
sd(redWine$pH)

#White wine standard deviations
sd(whiteWine$quality)
sd(whiteWine$alcohol)
sd(whiteWine$residual.sugar)
sd(whiteWine$pH)

```

```{r visualizeWine}
#1.  Create visualizations for the data
#heat maps, histograms and scatter plots

#Histograms
hist(redWine$quality, main = "Red Wine Distribution", xlab = "Quality with Mean = 5.636 and SD = 0.8076", col ="red4")
hist(whiteWine$quality, main = "White Wine Distribution", xlab = "Quality with Mean = 5.878 and SD = 0.8856", col = "lemonchiffon")

library(grid, warn.conflicts = FALSE) # Eliminate version warning when library is installed
library(gridExtra, warn.conflicts = FALSE)
library (ggplot2, warn.conflicts = FALSE)

h1 <- ggplot(aes(density), data = redWine) + geom_histogram(bins = 30,fill= "tomato3",color="white")
h1 <- h1 + ggtitle("Density Distribution") +theme(axis.title.x = element_blank())

h2 <- ggplot(aes(alcohol), data = redWine) + geom_histogram(bins = 30, fill= "tomato3",color="white")
h2 <- h2 + ggtitle("Alcohol Distribution") +theme(axis.title.x = element_blank())

h3 <- ggplot(aes(residual.sugar), data = redWine) + geom_histogram(bins = 7, fill= "tomato3",color="white")
h3 <- h3 + ggtitle("Sugar Distribution") + theme(axis.title.x = element_blank())

h4 <- ggplot(aes(pH), data = redWine) + geom_histogram(bins = 7, fill= "tomato3",color="white")
h4 <- h4 + ggtitle("pH Distribution")+theme(axis.title.x = element_blank())

grid.arrange(h1,h2,h3,h4,ncol=2)

g1 <- ggplot(aes(density), data = whiteWine) + geom_histogram(bins = 25,fill= "lightgoldenrod2",color="white")
g1 <- g1 +  ggtitle("Density Distribution") + theme(axis.title.x = element_blank())

g2 <- ggplot(aes(alcohol), data = whiteWine) + geom_histogram(bins = 20, fill= "lightgoldenrod2",color="white")
g2 <- g2 + ggtitle("Alcohol Distribution") + theme(axis.title.x = element_blank())

g3 <- ggplot(aes(residual.sugar), data = whiteWine) + geom_histogram(bins = 7, fill= "lightgoldenrod2",color="white")
g3 <- g3 + ggtitle("Sugar Distribution") + theme(axis.title.x = element_blank())

g4 <- ggplot(aes(pH), data = whiteWine) + geom_histogram(bins = 7, fill= "lightgoldenrod2",color="white")
g4 <- g4 + ggtitle("pH Distribution") + theme(axis.title.x = element_blank())

grid.arrange(g1,g2,g3,g4,ncol=2)
```

```{r correlationWine}
#1. Create the correlation matrix

#Red Wine Correlation Matrix

#install.packages("corrplot")
library(corrplot, warn.conflicts = FALSE)
red_cor <- cor(redWine)
round(red_cor, 2)
corrplot(red_cor, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
#Positive correlations are displayed in blue and negative correlations in red color. Color intensity and the size of the circle are proportional to the correlation coefficients.

#Correlation matrix with numbers
corrplot(red_cor, method = 'number', type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

#White Wine Correlation Matrix

#install.packages("corrplot")
library(corrplot,warn.conflicts = FALSE)
white_cor <- cor(whiteWine)
round(white_cor, 2)
corrplot(white_cor, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

#Correlation matrix with numbers
corrplot(white_cor, method = 'number',type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

#Quality correlations
dfred_cor<-data.frame(red_cor)
dfwhite_cor<-data.frame(white_cor)
names<-row.names(dfred_cor)

QualityCor<-round(cbind(dfred_cor$quality,dfwhite_cor$quality),digits=4)
colnames(QualityCor)<-c("Red Quality", "White Quality")
row.names(QualityCor)<-names
View(QualityCor)

##Reference: http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software
```
```{r Tree Diagrams}
# Taking a look at the correlation coefficients from the previous file, we see that density is moderately correlated with fixed.acidity (r=0.67) and alcohol (r=âˆ’0.5). Fixed.acidity is moderately correlated with citric.acid (r= 0.67) and ph (r=-0.68). Citric.acid is moderately correlated with volatile.acidity (r=-0.55) and ph (r=-0.54). Free.sulfur.dioxide and total.sulfur.dioxide are also moderately correlated with each other (r=0.67) although this is trivially known because free sulfur dioxide is incorporated into the total sulfur dioxide. Aside from that correlations are all very low, including quality.

#table preview
knitr::kable(head(redWine))

#install.packages("plotly")
library(plotly, warn.conflicts = FALSE) #data visualization

#Converting the quality attribute from numeric to factor
redWine$bquality <- ifelse(redWine$quality < 5, "Mediocre", ifelse(redWine$quality <7 , "Average", ifelse(redWine$quality >6, "Excellent", NA)))

whiteWine$bquality <- ifelse(whiteWine$quality < 5, "Mediocre", ifelse(whiteWine$quality <7 , "Average", ifelse(whiteWine$quality >6, "Excellent", NA)))

#BoxPlots

#Red Wine
##Important Note for the Red Wine: Excellent wine is high on alcohol and low in volatile.acidity
plot_ly(data = redWine, x = ~bquality, y = ~alcohol, color = ~bquality, type = "box", colors = "Dark2")
plot_ly(data = redWine, x = ~bquality, y = ~volatile.acidity, color = ~bquality, type = "box", colors = "Dark2")


#White Wine
##Important Note for the White Wine: Excellent wine is high on alcohol and low in density
plot_ly(data = whiteWine, x = ~bquality, y = ~alcohol, color = ~bquality, type = "box", colors = "Dark2")
plot_ly(data = whiteWine, x = ~bquality, y = ~density, color = ~bquality, type = "box", colors = "Dark2")

```

```{r trees red Wine}
#Model Training (Regression Tree for Red Wine)
#install.packages("rpart")
#install.packages("rpart.plot")
#install.packages("rattle")
library(rpart,warn.conflicts = FALSE)
library(rpart.plot,warn.conflicts = FALSE)
library(rattle, warn.conflicts = FALSE)

#Recursive Partitioning and Regression Trees **Red Wine**
#Reference:https://www.rdocumentation.org/packages/rpart/versions/4.1-15/topics/rpart
nrows<-nrow(redWine)
cutPoint<- floor(nrows/3*2)
cutPoint
rand<-sample(1:nrows)
#training set Red Wine
red_train <- redWine[rand[1:cutPoint],]

#test set Red Wine
red_test <- redWine[rand[(cutPoint+1:nrows)],]
red_test<-na.omit(red_test)

w.rpart <- rpart(quality ~. , data = red_train)

w.rpart

rpart.plot(w.rpart, digits = 3)
fancyRpartPlot(w.rpart)
prediction <- predict(w.rpart,red_test)

RWine.Pred<-as.matrix(summary(prediction)) # Summarizing results fro red Wine
colnames(RWine.Pred)<-"RWine.Pred" # Add column names
RWine.Test<-as.matrix(summary(red_test$quality))
colnames(RWine.Test)<-"RWine.Test"

RwineTree.Df<- data.frame(RWine.Pred,RWine.Test)

##Important Note for the Red Wine: From the summaries above, the model does really great at estimating the bad and the excellent wine

#Mean Absolute Error Function
MAE <- function(actual, predicted){
  MAE<-mean(abs(actual - predicted))
}

MAE.Red<-MAE(red_test$quality, prediction)
MAE.Red

##Important Note for the Red Wine: MAE= 0.39
```

```{r trees White Wine}
#Recursive Partitioning and Regression Trees **White Wine**
nrows.w<-nrow(whiteWine)
cutPoint.w<- floor(nrows.w/3*2)
cutPoint.w
rand.w<-sample(1:nrows.w)
#training set White Wine
white_train <- whiteWine[rand.w[1:cutPoint.w],]

#test set White Wine
white_test <- whiteWine[rand.w[(cutPoint.w+1:nrows.w)],]
white_test<-na.omit(white_test)

w.rpartw <- rpart(quality ~. , data = white_train)

w.rpartw

rpart.plot(w.rpartw, digits = 3)
fancyRpartPlot(w.rpartw)
prediction.w <- predict(w.rpartw,white_test)

WWine.Pred<-as.matrix(summary(prediction.w)) #Summarize results for White Wine
colnames(WWine.Pred)<-"WWine.Pred" #Add column name
WWine.Test<-as.matrix(summary(white_test$quality))
colnames(WWine.Test)<-"WWine.Test"
##Important Note for the White Wine: From the summaries above, the model does really great at estimating the bad and the excellent wine

#Mean Absolute Error
MAE.White<-MAE(white_test$quality, prediction.w)
MAE.White
##Important Note for the white Wine: MAE= 0.38
```

```{r trees Consolidated}
##Consolidated Results for both Wine types

wineTree.Df<- round(cbind(WWine.Pred,RWine.Pred,WWine.Test,RWine.Test),2)
wineTree.Df
```
