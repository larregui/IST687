---
title: "Tree_Diagrams"
author: "Laura Larregui, John Christman, Angela Rivera"
date: "12/3/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Taking a look at the correlation coefficients from the previous file, we see that density is moderately correlated with fixed.acidity (r=0.67) and alcohol (r=âˆ’0.5). Fixed.acidity is moderately correlated with citric.acid (r= 0.67) and ph (r=-0.68). Citric.acid is moderately correlated with volatile.acidity (r=-0.55) and ph (r=-0.54). Free.sulfur.dioxide and total.sulfur.dioxide are also moderately correlated with each other (r=0.67) although this is trivially known because free sulfur dioxide is incorporated into the total sulfur dioxide. Aside from that correlations are all very low, including quality.

```{r visualization}

readURL <- function(inputURL)  #Begin function named readURL that takes a URL
{
  csvFile <- read.csv(url(inputURL), sep = ';')  #assign the results of the URL call as a csv file to a dataframe named csvFile. Added sep = ';' to seperate the data into columns
  return(csvFile)  # return the dataframe
}

redWine <- readURL("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv")
whiteWine <- readURL("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv")

# Verify no NAs
redWine <- na.omit(redWine)
whiteWine<-na.omit (whiteWine)
#table preview
knitr::kable(head(redWine))

#install.packages("plotly")
library(plotly) #data visualization

#Converting the quality attribute from numeric to factor
redWine$bquality <- ifelse(redWine$quality < 5, "Mediocre", ifelse(redWine$quality <7 , "Average", ifelse(redWine$quality >6, "Excellent", NA)))

plot_ly(data = redWine, x = ~bquality, y = ~alcohol, color = ~bquality, type = "box", colors = "Dark2")
plot_ly(data = redWine, x = ~bquality, y = ~density, color = ~bquality, type = "box", colors = "Dark2")

##Important Note for the Red Wine: Excellent wine is high on alcohol and low in density

```
##Important Note for the Red Wine: Excellent wine is high on alcohol and low in density

#Model Training (Regression Tree)
```{r trees}

#install.packages("rpart")
#install.packages("rpart.plot")
#install.packages("rattle")
library(rpart)
library(rpart.plot)
library(rattle)

#Recursive Partitioning and Regression Trees
#Reference:https://www.rdocumentation.org/packages/rpart/versions/4.1-15/topics/rpart
nrows<-nrow(redWine)
cutPoint<- floor(nrows/3*2)
cutPoint
rand<-sample(1:nrows)
#training set
red_train <- redWine[rand[1:cutPoint],]

#test set
red_test <- redWine[rand[(cutPoint+1:nrows)],]
red_test<-na.omit(red_test)

w.rpart <- rpart(quality ~. , data = red_train)

w.rpart

rpart.plot(w.rpart, digits = 3)
fancyRpartPlot(w.rpart)
prediction <- predict(w.rpart,red_test)

summary(prediction)
summary(red_test$quality)

##Important Note for the Red Wine: From the summaries above, the model does really great at estimating the bad and the excellent wine

#Mean Absolute Error
MAE <- function(actual, predicted){
  mean(abs(actual - predicted))
}

MAE(red_test$quality, prediction)

##Important Note for the Red Wine: MAE= 0.39
```
##Important Note for the Red Wine: From the summaries above, the model does really great at estimating the bad and the excellent wine
##Important Note for the Red Wine: MAE= 0.39

#Model Tree
###A model tree differs from a regression tree due to the fact that it runs multiple regression models at every node.
```{r model tree}
#install.packages("RWeka")
library(RColorBrewer)
library(rattle)
library(RWeka)
#building the model
m.m5p <- M5P(quality ~. , data = red_train)

# building the predictor
p.m5p <- predict(m.m5p, red_test)

m.m5p

MAE(redWine$quality, p.m5p)
```
```{r tree2}
installed.packages("tree")
library(tree) 
# predicting the cquality
redWine$cquality <- ifelse(redWine$quality < 5, "Mediocre", ifelse(redWine$quality >6, "Excellent", NA))
bquality<- as.factor(redWine$cquality)
tree <- plot.tree(formula = cquality ~ ., data = red_train, 
             method = "class",
             control = tree.control(nobs = nrow(red_train),
                                          mincut = 5,
                                          minsize = 10,
                                          mindev = .003))
summary(tree)
plot(tree, type = "uniform")
text(tree, pretty = 0, cex = 1, col = "blue")
title("Classification Tree")
```
